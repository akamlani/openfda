{
 "metadata": {
  "name": "",
  "signature": "sha256:2a3bac9dcbd3eb10b5a2b27adcd96475eba48f8b83c9f5976a96f132a2ba67fa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import time\n",
      "from sklearn.utils import shuffle\n",
      "\n",
      "print pd.get_option('display.max_columns')\n",
      "pd.set_option(\"display.max_columns\",100)\n",
      "print pd.get_option('display.max_columns')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100\n",
        "100\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load openfda.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2 as ulib\n",
      "import json\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pandas.io.json import json_normalize\n",
      "\n",
      "import yaml\n",
      "from pprint import pprint\n",
      "\n",
      "import filters as filters\n",
      "import utilities as utl\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "\n",
      "\n",
      "def read_credentials():\n",
      "\t\"\"\"read in the configuration API Key\"\"\"\n",
      "\t# openfda is rate limited without api key\n",
      "\t# No API Key: 40 requests per minute (per IP Address): 1000 requests per day (per IP Address)\n",
      "\t# API Key:    240 requests per minute (per key):       120000 requests per day (per key)\n",
      "\tcredentials = yaml.load(open('../config/api_cred.yml'))\n",
      "\tapi_key = credentials['openfda_key']\n",
      "\treturn api_key\n",
      "\n",
      "\n",
      "def openfda_request(query, count, api_key, limit=100, skip=0):\n",
      "\t\"\"\"openfda Restful API Request\"\"\"\n",
      "\trequest_string ='https://api.fda.gov/drug/event.json?api_key={0}&search={1}&count={2}&limit={3}&skip={4}'\n",
      "\trequest = request_string.format(api_key, query, count, limit, skip)\n",
      "\tprint \"Send Query as:\\n{0}\".format(request)\n",
      "\tresponse=ulib.urlopen(request)\n",
      "\tfda_data=json.load(response)\n",
      "\trecords_received = len(fda_data[\"results\"]) \n",
      "\tprint \"Result Count: {0}\".format(records_received)\n",
      "\treturn fda_data, records_received \n",
      "\n",
      "\n",
      "def load_from_file():\n",
      "\tresults=[]\n",
      "\twith open(\"./../data/openfda_data.json\", 'r') as f: results = json.load(f)\n",
      "\t#this returns a string, not dictionary, use for print only: results = json.dumps(results, indent=4)\n",
      "\tprint \"file version\", type(results)\n",
      "\treturn results\n",
      "\n",
      "\n",
      "def load_from_api():\n",
      "\tresults = []\n",
      "\tmax_records = 1000\n",
      "\trecord_count = 100; offset=0\n",
      "\tapi_key = read_credentials()\n",
      "\tcount, search = get_search_query()\t\n",
      "\t# limited by OpenFDA, maximum records at a time is 100 via search filters, use pagination\n",
      "\tfor i in range(max_records/record_count):\n",
      "\t\trecords, records_received = openfda_request(search, count, api_key, record_count, offset)\n",
      "\t\toffset += records_received\n",
      "\t\tresults += records['results']\n",
      "\t\tprint \"Total Count: {0}\".format(len(results))\n",
      "\n",
      "\twith open(\"./../data/openfda_data.json\", 'w') as f: json.dump(results, f, indent=4, ensure_ascii=False)\n",
      "\tprint \"api version\", type(results)\n",
      "\treturn results\n",
      "\n",
      "def get_search_query():\n",
      "\tcount = ''\n",
      "\tsearch = 'patient.patientonsetage:[65+TO+99]'\n",
      "\tsearch+= '+AND+_exists_:serious+AND+serious:1'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugcharacterization'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugindication+AND+patient.drug.drugindication:hypertension'\n",
      "\n",
      "\t\"\"\"\n",
      "\tsearch+= '+AND+_exists_:occurcountry'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.actiondrug'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugstartdate'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugenddate'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugtreatmentduration'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugbatchnumb'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugadministrationroute'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugrecurreadministration'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugdosageform'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugcumulativedosagenumb+AND+_exists_:patient.drug.drugcumulativedosageunit'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugintervaldosagedefinition+AND+_exists_:patient.drug.drugintervaldosageunitnumb'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugseparatedosagenumb+AND+_exists_:patient.drug.drugstructuredosagenumb'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugstructuredosageunit'\n",
      "\n",
      "\tsearch+= '+AND+_exists_:patient.reaction.reactionoutcome+AND+patient.reaction.reactionoutcome:3'\n",
      "\tsearch+= '+AND+_exists_:patient.reaction.reactionoutcome'\n",
      "\n",
      "\tsearch+= '+AND+_exists_:patient.patientonsetage+AND+_exists_:patient.patientsex+AND+_exists_:patient.patientweight'\n",
      "\t\"\"\"\n",
      "\treturn count, search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def extract_embedded_extensions_df(df):\n",
      "\t\"\"\"extract condition embedded list of extensions\"\"\"\n",
      "\tdrug_list = []\n",
      "\tfor drug in df:\n",
      "\t\td = {};      \n",
      "\t\tfor label in drug.keys(): \n",
      "\t\t\tfor f_id in [filters.drug_id, filters.drug_span_id, \n",
      "\t\t\t\t\t\t filters.drug_dosage_id, filters.drug_openfda]:\n",
      "\t\t\t\tif label in f_id:\td[label] = drug[label]\n",
      "\t\tdrug_list.append(d)\n",
      "\treturn drug_list\n",
      "\n",
      "\n",
      "def extract_extensions_df(df, features, d, extension):\n",
      "\t\"\"\"extract condtional extensions\"\"\"\n",
      "\tfor label in extension: \n",
      "\t    if label in features: d[label] = df[label]\n",
      "\treturn d    \n",
      "\n",
      "\n",
      "def extract_df(df, features, obj):\n",
      "\t\"\"\"deal with finding embedded dictionary information\"\"\"\n",
      "\t# determine if these labels exit in the row and pull out neceaary informationoo\n",
      "\t# no embedded lists are pulled out at this point\n",
      "\td = {}\t\t\n",
      "\tfor label in features: \n",
      "\t\tfor f_id in [filters.report_id, filters.incident_id, filters.patient_id, filters.reactions_id]:\n",
      "\t\t\tif label in f_id:  d[label] = df[label]\n",
      "\t# some values are dependent upon conditional values: futher filtering\n",
      "\tcond = ('serious' in features) and (int(df['serious']) == 1) \n",
      "\tif(cond): extract_extensions_df(df, features, d, filters.incident_id_ext)\n",
      "\telse: \n",
      "\t\tfor i in filters.incident_id_ext: d[i] = float('NaN')  \n",
      "\t# serious -> serious deaths -> patient deathdate\n",
      "\tcond = (('seriousnessdeath' in features) and df['seriousnessdeath'] == str(1))\n",
      "\tif (cond): extract_extensions_df(df, features, d, filters.patient_id_ext)\n",
      "\telse:  \n",
      "\t\tfor i in filters.patient_id_ext: d[i] = float('NaN')\n",
      "\tobj.append(d)\n",
      "   \n",
      "\n",
      "def parse_response(json_response):\n",
      "\t\"\"\"parse the json dictionaries response data\"\"\"\n",
      "\tobj = []\n",
      "\tdf = json_normalize(json_response)\n",
      "\n",
      "\tdf.apply(lambda x: extract_df(x, df.columns, obj), axis=1)\t\n",
      "\tdf_report = pd.DataFrame(obj, columns=obj[0].keys())\n",
      "\tdf_reactions = df_report['patient.reaction']\n",
      "\tpatient_drugs = df['patient.drug'].apply(extract_embedded_extensions_df)\n",
      "\tdf_patient_drugs = pd.DataFrame(patient_drugs)\n",
      "\treturn df_report, df_reactions, df_patient_drugs\n",
      "\n",
      "\n",
      "def build_relational_tables(df_report, df_reactions, df_patient_drugs):\n",
      "\t\"several tables each sharing unique identifier of safetyreportid\"\n",
      "\t# (1) report table (report_id, incidents, incidents extensions)\n",
      "\tmissing_col = list(set(filters.report_id).difference(df_report.columns))\n",
      "\tcol_header = list(set(filters.report_id).difference(missing_col))\n",
      "\treporting_table = df_report[col_header].reindex_axis(filters.report_id, axis=1)\n",
      "\tmissing_col = list(set(filters.incident_id).difference(df_report.columns))\n",
      "\tcol_header = list(set(filters.incident_id).difference(missing_col))\n",
      "\treporting_table[col_header] = df_report[col_header]\n",
      "\tmissing_col = list(set(filters.incident_id_ext).difference(df_report.columns))\n",
      "\tcol_header = list(set(filters.incident_id_ext).difference(missing_col))\n",
      "\treporting_table[col_header] = df_report[col_header]\n",
      "\treporting_table.set_index('safetyreportid')\n",
      "\t# (2) patient table\n",
      "\tpatient_table = df_report[['safetyreportid'] + filters.patient_id + filters.patient_id_ext]\n",
      "\tpatient_table.set_index('safetyreportid')\n",
      "\t# (3) patient reactions table\n",
      "\treaction_table = utl.convert_to_hiearchial_fmt(df_reactions, patient_table['safetyreportid'], \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t   ['safetyreportid', 'reactionmeddrapt'],  \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t   ['reactionmeddrapt'])#'reactionoutcome', 'reactionoutcome'\n",
      "\t# (4) drug prescriptions table\n",
      "\tprescriptions_table = utl.convert_to_multicol_hiearchial_fmt(df_patient_drugs['patient.drug'], \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t patient_table['safetyreportid'], \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t ['safetyreportid'] + \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t filters.drug_id + filters.drug_span_id + \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t filters.drug_dosage_id) # +\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t #filters.open_drug_harmon_id +\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t #filters.open_pharm_drug_class_id +\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t #filters.open_ingredient_id +\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t #filters.open_ingredient_labels_id)\n",
      "\n",
      "\treturn patient_table, reaction_table, reporting_table, prescriptions_table\n",
      "\n",
      "\n",
      "\n",
      "def imputate_relational_tables(patient_table, reaction_table, reporting_table, prescriptions_table):\n",
      "\t\"\"\"imputate data in relational tables\"\"\"\n",
      "\t# patient information\t\n",
      "\tpatient_table_ = patient_table.copy()\n",
      "\tpatient_table_['patient.patientdeath.patientdeathdate'] = pd.to_datetime(patient_table_['patient.patientdeath.patientdeathdate']) \n",
      "\tnumeric_features = ['patient.patientsex', 'patient.patientonsetage', 'patient.patientweight']\n",
      "\tfor n in numeric_features: patient_table_[n] = patient_table_[n].convert_objects(convert_numeric=True,convert_dates=True)\n",
      " \tfor col in ['patient.patientsex', 'patient.patientonsetage', 'patient.patientweight']:\n",
      "\t\tavg = round(patient_table_[col][patient_table_[col].notnull()].mean())\n",
      "\t\tpatient_table_[col].fillna(avg, inplace=True)\n",
      "\n",
      "\t# reporting table\n",
      "\treporting_table['receivedate'] = pd.to_datetime(reporting_table['receivedate'])\n",
      "\treporting_table['receiptdate'] = pd.to_datetime(reporting_table['receiptdate'])\n",
      "\treporting_table['reportage'] = (reporting_table['receiptdate'] - reporting_table['receivedate'])/ np.timedelta64(1, 's') \n",
      "\treporting_table['serious'] = reporting_table['serious'].apply(lambda x: float(x))\n",
      "\t#le_rep, reporting_table = utl.encode_labels(reporting_table, 'occurcountry')\t\n",
      "\treport_filters = ['primarysource.qualification'] + filters.incident_id + filters.incident_id_ext\n",
      "\tfor col in report_filters: \n",
      "\t\tif col in reporting_table.columns: reporting_table[col] = reporting_table[col].convert_objects(convert_numeric=True)\n",
      "\treporting_table['primarysource.qualification'] = reporting_table['primarysource.qualification'].fillna(0)\t\n",
      "\tfor label in filters.incident_id_ext:\n",
      "\t\tif label in reporting_table.columns: reporting_table[label] = reporting_table[label].fillna(0)\n",
      "\treporting_table.drop(['companynumb', 'duplicate'], axis=1, inplace=True)\n",
      "\treporting_table.drop(['receivedate', 'receiptdate'], axis=1, inplace=True)\n",
      "\n",
      "\t# prescriptions table\n",
      "\tcol = ['safetyreportid', 'medicinalproduct', 'drugindication', 'drugcharacterization', 'actiondrug']\n",
      "\tdrug_table = prescriptions_table.copy()\n",
      "\tdrug_table = drug_table[col]\n",
      "\tdrug_count = len(drug_table['medicinalproduct'].unique())\n",
      "\tdrug_table['drugindication'] = drug_table['drugindication'].fillna('')\n",
      "\tle_di, drug_table = utl.encode_labels(drug_table, 'drugindication')\t\n",
      "\tle_med, drug_table = utl.encode_labels(drug_table, 'medicinalproduct')\t\n",
      "\tdrug_table['actiondrug'] = drug_table['actiondrug'].fillna(0)\n",
      "\tdrug_table['actiondrug'] = drug_table['actiondrug'].convert_objects(convert_numeric=True)\n",
      "\tdrug_table['drugcharacterization'] = drug_table['drugcharacterization'].convert_objects(convert_numeric=True)\n",
      "\n",
      "\t# reaction_table\n",
      "\t# reaction_outcome_labels = np.sort(reaction_table['reactionoutcome'].unique())\n",
      "\t# reaction_table['reactionoutcome'] = reaction_table['reactionoutcome'].convert_objects(convert_numeric=True)\t\n",
      "\tle_react, reaction_table = utl.encode_labels(reaction_table, 'reactionmeddrapt')\n",
      "\n",
      "\treturn reporting_table, patient_table_, drug_table, reaction_table, [le_di, le_med, le_react]\n",
      "\n",
      "\n",
      "def prepare_data(samples):\t\n",
      "\t# Parse Information\n",
      "\tdf_report, df_reactions, df_patient_drugs = parse_response(samples) \n",
      "\t# Build Relational Tables\n",
      "\tpatient_table, reaction_table, reporting_table, prescriptions_table = \\\n",
      "\tbuild_relational_tables(df_report, df_reactions, df_patient_drugs)\n",
      "\t# Imputate data (not used much currently)\n",
      "\treporting_table, patient_table_, drug_table, reaction_table, le_l = \\\n",
      "\timputate_relational_tables(patient_table, reaction_table, reporting_table, prescriptions_table)\n",
      "\t# Reverse per Label Datapoints and unique labels\n",
      "\treaction_labels =  le_l[2].inverse_transform(reaction_table['reactionmeddrapt'])\n",
      "\tdrug_labels = le_l[1].inverse_transform(drug_table['medicinalproduct'])\t\t\n",
      "\t# Create Patient/Drug Matrix\n",
      "\tnames_l, drugs_l, dg_v = drug_binary_vec(drug_table)\n",
      "\tname_drug_df = pd.DataFrame(dg_v, index=names_l, columns=drugs_l)\n",
      "\tprint \"parse binary vector shape: {0}\".format(name_drug_df.shape)\n",
      "\treturn drug_table, reaction_table, name_drug_df, le_l\n",
      "\n",
      "\n",
      "def group_drugs(drug_table):\n",
      "\t\"\"\"group drugs into a list to prepare for ML algorithms\"\"\"\n",
      "\tv = []\n",
      "\tdrug_table_v = drug_table.copy()\n",
      "\t#drug_table_v = drug_table_v.reset_index()\n",
      "\t#drug_table_v.drop(['level_0', 'level_1'], axis=1, inplace=True)\n",
      "\tdrug_table_v = drug_table_v.groupby('medicinalproduct', sort=True, as_index=False)\n",
      "\tfor name, group in drug_table_v: v.append(group.to_dict())\n",
      "\t\n",
      "\td_v = []\n",
      "\tfor de in v: \n",
      "\t\td = {}; length = len(de['medicinalproduct']);\n",
      "\t\tfor key,value in de.iteritems():\n",
      "\t\t\td_l = []\n",
      "\t\t\tfor i in range(length):\n",
      "\t\t\t\tfor k, v in value.iteritems(): d[key] =  v\n",
      "\t\t\t\td_l.append(d)\n",
      "\t\td_v.append(d_l)\n",
      "\t\n",
      "\treturn d_v\n",
      "\t\n",
      "\n",
      "def drug_binary_vec(drug_table):\n",
      "\t\"\"\"group report id drugs and binarize the data\"\"\"\n",
      "\tdg_v = []; names_l = []; drugs_l = []\n",
      "\tdrug_p = pd.get_dummies(drug_table['medicinalproduct']).reset_index()\n",
      "\tdrug_p.drop('level_1', axis=1, inplace=True)\n",
      "\tdg =  drug_p.groupby('level_0')\n",
      "\tfor name, group in dg:\n",
      "\t\tcol = group.columns - ['level_0']\n",
      "\t\tdf = group[col]; t = [0] * len(col)\n",
      "\t\tfor index, row in df.iterrows(): t += row[col]\n",
      "\t\tdg_v.append(t)\n",
      "\t\tnames_l.append(name)\n",
      "\t\tdrugs_l = col\n",
      "\n",
      "\tdg_v = np.array(dg_v)\n",
      "\tdg_v = preprocessing.binarize(dg_v)\n",
      "\treturn names_l, drugs_l, dg_v\n",
      "\n",
      "def drug_reaction_binary_vec(drug_reaction):\n",
      "\tdr_v = []; drugs_l = []; react_l = [] \n",
      "\tdrug_reaction = pd.get_dummies(drug_reaction['reactionmeddrapt']).reset_index()\n",
      "\tdrug_reaction = drug_reaction.groupby('medicinalproduct')\n",
      "\tfor name, group in drug_reaction: \n",
      "\t\tcol = group.columns - ['safetyreportid', 'medicinalproduct']\n",
      "\t\tdf = group[col]; t = [0] * len(col)\n",
      "\t\tfor index, row in df.iterrows(): t += row[col]\n",
      "\t\tdr_v.append(t)\n",
      "\t\tdrugs_l.append(name)\n",
      "\t\treact_l = col\n",
      "\n",
      "\tdr_v = np.array(dr_v)\n",
      "\tdr_v = preprocessing.binarize(dr_v)\n",
      "\treturn drugs_l, react_l, dr_v\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2 as ulib\n",
      "import json\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pandas.io.json import json_normalize\n",
      "\n",
      "import yaml\n",
      "from pprint import pprint\n",
      "\n",
      "import filters as filters\n",
      "import utilities as utl\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "\n",
      "\n",
      "def read_credentials():\n",
      "\t\"\"\"read in the configuration API Key\"\"\"\n",
      "\t# openfda is rate limited without api key\n",
      "\t# No API Key: 40 requests per minute (per IP Address): 1000 requests per day (per IP Address)\n",
      "\t# API Key:    240 requests per minute (per key):       120000 requests per day (per key)\n",
      "\tcredentials = yaml.load(open('../config/api_cred.yml'))\n",
      "\tapi_key = credentials['openfda_key']\n",
      "\treturn api_key\n",
      "\n",
      "\n",
      "def openfda_request(query, count, api_key, limit=100, skip=0):\n",
      "\t\"\"\"openfda Restful API Request\"\"\"\n",
      "\trequest_string ='https://api.fda.gov/drug/event.json?api_key={0}&search={1}&count={2}&limit={3}&skip={4}'\n",
      "\trequest = request_string.format(api_key, query, count, limit, skip)\n",
      "\tprint \"Send Query as:\\n{0}\".format(request)\n",
      "\tresponse=ulib.urlopen(request)\n",
      "\tfda_data=json.load(response)\n",
      "\trecords_received = len(fda_data[\"results\"]) \n",
      "\tprint \"Result Count: {0}\".format(records_received)\n",
      "\treturn fda_data, records_received \n",
      "\n",
      "\n",
      "def load_from_file():\n",
      "\tresults=[]\n",
      "\twith open(\"./../data/openfda_data.json\", 'r') as f: results = json.load(f)\n",
      "\t#this returns a string, not dictionary, use for print only: results = json.dumps(results, indent=4)\n",
      "\tprint \"file version\", type(results)\n",
      "\treturn results\n",
      "\n",
      "\n",
      "def load_from_api():\n",
      "\tresults = []\n",
      "\tmax_records = 1000\n",
      "\trecord_count = 100; offset=0\n",
      "\tapi_key = read_credentials()\n",
      "\tcount, search = get_search_query()\t\n",
      "\t# limited by OpenFDA, maximum records at a time is 100 via search filters, use pagination\n",
      "\tfor i in range(max_records/record_count):\n",
      "\t\trecords, records_received = openfda_request(search, count, api_key, record_count, offset)\n",
      "\t\toffset += records_received\n",
      "\t\tresults += records['results']\n",
      "\t\tprint \"Total Count: {0}\".format(len(results))\n",
      "\n",
      "\twith open(\"./../data/openfda_data.json\", 'w') as f: json.dump(results, f, indent=4, ensure_ascii=False)\n",
      "\tprint \"api version\", type(results)\n",
      "\treturn results\n",
      "\n",
      "def get_search_query():\n",
      "\tcount = ''\n",
      "\tsearch = 'patient.patientonsetage:[65+TO+99]'\n",
      "\tsearch+= '+AND+_exists_:serious+AND+serious:1'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugcharacterization'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugindication+AND+patient.drug.drugindication:hypertension'\n",
      "\n",
      "\t\"\"\"\n",
      "\tsearch+= '+AND+_exists_:occurcountry'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.actiondrug'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugstartdate'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugenddate'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugtreatmentduration'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugbatchnumb'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugadministrationroute'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugrecurreadministration'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugdosageform'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugcumulativedosagenumb+AND+_exists_:patient.drug.drugcumulativedosageunit'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugintervaldosagedefinition+AND+_exists_:patient.drug.drugintervaldosageunitnumb'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugseparatedosagenumb+AND+_exists_:patient.drug.drugstructuredosagenumb'\n",
      "\tsearch+= '+AND+_exists_:patient.drug.drugstructuredosageunit'\n",
      "\n",
      "\tsearch+= '+AND+_exists_:patient.reaction.reactionoutcome+AND+patient.reaction.reactionoutcome:3'\n",
      "\tsearch+= '+AND+_exists_:patient.reaction.reactionoutcome'\n",
      "\n",
      "\tsearch+= '+AND+_exists_:patient.patientonsetage+AND+_exists_:patient.patientsex+AND+_exists_:patient.patientweight'\n",
      "\t\"\"\"\n",
      "\treturn count, search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def extract_embedded_extensions_df(df):\n",
      "\t\"\"\"extract condition embedded list of extensions\"\"\"\n",
      "\tdrug_list = []\n",
      "\tfor drug in df:\n",
      "\t\td = {};      \n",
      "\t\tfor label in drug.keys(): \n",
      "\t\t\tfor f_id in [filters.drug_id, filters.drug_span_id, \n",
      "\t\t\t\t\t\t filters.drug_dosage_id, filters.drug_openfda]:\n",
      "\t\t\t\tif label in f_id:\td[label] = drug[label]\n",
      "\t\tdrug_list.append(d)\n",
      "\treturn drug_list\n",
      "\n",
      "\n",
      "def extract_extensions_df(df, features, d, extension):\n",
      "\t\"\"\"extract condtional extensions\"\"\"\n",
      "\tfor label in extension: \n",
      "\t    if label in features: d[label] = df[label]\n",
      "\treturn d    \n",
      "\n",
      "\n",
      "def extract_df(df, features, obj):\n",
      "\t\"\"\"deal with finding embedded dictionary information\"\"\"\n",
      "\t# determine if these labels exit in the row and pull out neceaary informationoo\n",
      "\t# no embedded lists are pulled out at this point\n",
      "\td = {}\t\t\n",
      "\tfor label in features: \n",
      "\t\tfor f_id in [filters.report_id, filters.incident_id, filters.patient_id, filters.reactions_id]:\n",
      "\t\t\tif label in f_id:  d[label] = df[label]\n",
      "\t# some values are dependent upon conditional values: futher filtering\n",
      "\tcond = ('serious' in features) and (int(df['serious']) == 1) \n",
      "\tif(cond): extract_extensions_df(df, features, d, filters.incident_id_ext)\n",
      "\telse: \n",
      "\t\tfor i in filters.incident_id_ext: d[i] = float('NaN')  \n",
      "\t# serious -> serious deaths -> patient deathdate\n",
      "\tcond = (('seriousnessdeath' in features) and df['seriousnessdeath'] == str(1))\n",
      "\tif (cond): extract_extensions_df(df, features, d, filters.patient_id_ext)\n",
      "\telse:  \n",
      "\t\tfor i in filters.patient_id_ext: d[i] = float('NaN')\n",
      "\tobj.append(d)\n",
      "   \n",
      "\n",
      "def parse_response(json_response):\n",
      "\t\"\"\"parse the json dictionaries response data\"\"\"\n",
      "\tobj = []\n",
      "\tdf = json_normalize(json_response)\n",
      "\n",
      "\tdf.apply(lambda x: extract_df(x, df.columns, obj), axis=1)\t\n",
      "\tdf_report = pd.DataFrame(obj, columns=obj[0].keys())\n",
      "\tdf_reactions = df_report['patient.reaction']\n",
      "\tpatient_drugs = df['patient.drug'].apply(extract_embedded_extensions_df)\n",
      "\tdf_patient_drugs = pd.DataFrame(patient_drugs)\n",
      "\treturn df_report, df_reactions, df_patient_drugs\n",
      "\n",
      "\n",
      "def build_relational_tables(df_report, df_reactions, df_patient_drugs):\n",
      "\t\"several tables each sharing unique identifier of safetyreportid\"\n",
      "\t# (1) report table (report_id, incidents, incidents extensions)\n",
      "\tmissing_col = list(set(filters.report_id).difference(df_report.columns))\n",
      "\tcol_header = list(set(filters.report_id).difference(missing_col))\n",
      "\treporting_table = df_report[col_header].reindex_axis(filters.report_id, axis=1)\n",
      "\tmissing_col = list(set(filters.incident_id).difference(df_report.columns))\n",
      "\tcol_header = list(set(filters.incident_id).difference(missing_col))\n",
      "\treporting_table[col_header] = df_report[col_header]\n",
      "\tmissing_col = list(set(filters.incident_id_ext).difference(df_report.columns))\n",
      "\tcol_header = list(set(filters.incident_id_ext).difference(missing_col))\n",
      "\treporting_table[col_header] = df_report[col_header]\n",
      "\treporting_table.set_index('safetyreportid')\n",
      "\t# (2) patient table\n",
      "\tpatient_table = df_report[['safetyreportid'] + filters.patient_id + filters.patient_id_ext]\n",
      "\tpatient_table.set_index('safetyreportid')\n",
      "\t# (3) patient reactions table\n",
      "\treaction_table = utl.convert_to_hiearchial_fmt(df_reactions, patient_table['safetyreportid'], \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t   ['safetyreportid', 'reactionmeddrapt'],  \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t   ['reactionmeddrapt'])#'reactionoutcome', 'reactionoutcome'\n",
      "\t# (4) drug prescriptions table\n",
      "\tprescriptions_table = utl.convert_to_multicol_hiearchial_fmt(df_patient_drugs['patient.drug'], \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t patient_table['safetyreportid'], \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t ['safetyreportid'] + \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t filters.drug_id + filters.drug_span_id + \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t filters.drug_dosage_id) # +\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t #filters.open_drug_harmon_id +\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t #filters.open_pharm_drug_class_id +\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t #filters.open_ingredient_id +\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t #filters.open_ingredient_labels_id)\n",
      "\n",
      "\treturn patient_table, reaction_table, reporting_table, prescriptions_table\n",
      "\n",
      "\n",
      "\n",
      "def imputate_relational_tables(patient_table, reaction_table, reporting_table, prescriptions_table):\n",
      "\t\"\"\"imputate data in relational tables\"\"\"\n",
      "\t# patient information\t\n",
      "\tpatient_table_ = patient_table.copy()\n",
      "\tpatient_table_['patient.patientdeath.patientdeathdate'] = pd.to_datetime(patient_table_['patient.patientdeath.patientdeathdate']) \n",
      "\tnumeric_features = ['patient.patientsex', 'patient.patientonsetage', 'patient.patientweight']\n",
      "\tfor n in numeric_features: patient_table_[n] = patient_table_[n].convert_objects(convert_numeric=True,convert_dates=True)\n",
      " \tfor col in ['patient.patientsex', 'patient.patientonsetage', 'patient.patientweight']:\n",
      "\t\tavg = round(patient_table_[col][patient_table_[col].notnull()].mean())\n",
      "\t\tpatient_table_[col].fillna(avg, inplace=True)\n",
      "\n",
      "\t# reporting table\n",
      "\treporting_table['receivedate'] = pd.to_datetime(reporting_table['receivedate'])\n",
      "\treporting_table['receiptdate'] = pd.to_datetime(reporting_table['receiptdate'])\n",
      "\treporting_table['reportage'] = (reporting_table['receiptdate'] - reporting_table['receivedate'])/ np.timedelta64(1, 's') \n",
      "\treporting_table['serious'] = reporting_table['serious'].apply(lambda x: float(x))\n",
      "\t#le_rep, reporting_table = utl.encode_labels(reporting_table, 'occurcountry')\t\n",
      "\treport_filters = ['primarysource.qualification'] + filters.incident_id + filters.incident_id_ext\n",
      "\tfor col in report_filters: \n",
      "\t\tif col in reporting_table.columns: reporting_table[col] = reporting_table[col].convert_objects(convert_numeric=True)\n",
      "\treporting_table['primarysource.qualification'] = reporting_table['primarysource.qualification'].fillna(0)\t\n",
      "\tfor label in filters.incident_id_ext:\n",
      "\t\tif label in reporting_table.columns: reporting_table[label] = reporting_table[label].fillna(0)\n",
      "\treporting_table.drop(['companynumb', 'duplicate'], axis=1, inplace=True)\n",
      "\treporting_table.drop(['receivedate', 'receiptdate'], axis=1, inplace=True)\n",
      "\n",
      "\t# prescriptions table\n",
      "\tcol = ['safetyreportid', 'medicinalproduct', 'drugindication', 'drugcharacterization', 'actiondrug']\n",
      "\tdrug_table = prescriptions_table.copy()\n",
      "\tdrug_table = drug_table[col]\n",
      "\tdrug_count = len(drug_table['medicinalproduct'].unique())\n",
      "\tdrug_table['drugindication'] = drug_table['drugindication'].fillna('')\n",
      "\tle_di, drug_table = utl.encode_labels(drug_table, 'drugindication')\t\n",
      "\tle_med, drug_table = utl.encode_labels(drug_table, 'medicinalproduct')\t\n",
      "\tdrug_table['actiondrug'] = drug_table['actiondrug'].fillna(0)\n",
      "\tdrug_table['actiondrug'] = drug_table['actiondrug'].convert_objects(convert_numeric=True)\n",
      "\tdrug_table['drugcharacterization'] = drug_table['drugcharacterization'].convert_objects(convert_numeric=True)\n",
      "\n",
      "\t# reaction_table\n",
      "\t# reaction_outcome_labels = np.sort(reaction_table['reactionoutcome'].unique())\n",
      "\t# reaction_table['reactionoutcome'] = reaction_table['reactionoutcome'].convert_objects(convert_numeric=True)\t\n",
      "\tle_react, reaction_table = utl.encode_labels(reaction_table, 'reactionmeddrapt')\n",
      "\n",
      "\treturn reporting_table, patient_table_, drug_table, reaction_table, [le_di, le_med, le_react]\n",
      "\n",
      "\n",
      "def prepare_data(samples):\t\n",
      "\t# Parse Information\n",
      "\tdf_report, df_reactions, df_patient_drugs = parse_response(samples) \n",
      "\t# Build Relational Tables\n",
      "\tpatient_table, reaction_table, reporting_table, prescriptions_table = \\\n",
      "\tbuild_relational_tables(df_report, df_reactions, df_patient_drugs)\n",
      "\t# Imputate data (not used much currently)\n",
      "\treporting_table, patient_table_, drug_table, reaction_table, le_l = \\\n",
      "\timputate_relational_tables(patient_table, reaction_table, reporting_table, prescriptions_table)\n",
      "\t# Reverse per Label Datapoints and unique labels\n",
      "\treaction_labels =  le_l[2].inverse_transform(reaction_table['reactionmeddrapt'])\n",
      "\tdrug_labels = le_l[1].inverse_transform(drug_table['medicinalproduct'])\t\t\n",
      "\t# Create Patient/Drug Matrix\n",
      "\tnames_l, drugs_l, dg_v = drug_binary_vec(drug_table)\n",
      "\tname_drug_df = pd.DataFrame(dg_v, index=names_l, columns=drugs_l)\n",
      "\tprint \"parse binary vector shape: {0}\".format(name_drug_df.shape)\n",
      "\treturn drug_table, reaction_table, name_drug_df, le_l\n",
      "\n",
      "\n",
      "def group_drugs(drug_table):\n",
      "\t\"\"\"group drugs into a list to prepare for ML algorithms\"\"\"\n",
      "\tv = []\n",
      "\tdrug_table_v = drug_table.copy()\n",
      "\t#drug_table_v = drug_table_v.reset_index()\n",
      "\t#drug_table_v.drop(['level_0', 'level_1'], axis=1, inplace=True)\n",
      "\tdrug_table_v = drug_table_v.groupby('medicinalproduct', sort=True, as_index=False)\n",
      "\tfor name, group in drug_table_v: v.append(group.to_dict())\n",
      "\t\n",
      "\td_v = []\n",
      "\tfor de in v: \n",
      "\t\td = {}; length = len(de['medicinalproduct']);\n",
      "\t\tfor key,value in de.iteritems():\n",
      "\t\t\td_l = []\n",
      "\t\t\tfor i in range(length):\n",
      "\t\t\t\tfor k, v in value.iteritems(): d[key] =  v\n",
      "\t\t\t\td_l.append(d)\n",
      "\t\td_v.append(d_l)\n",
      "\t\n",
      "\treturn d_v\n",
      "\t\n",
      "\n",
      "def drug_binary_vec(drug_table):\n",
      "\t\"\"\"group report id drugs and binarize the data\"\"\"\n",
      "\tdg_v = []; names_l = []; drugs_l = []\n",
      "\tdrug_p = pd.get_dummies(drug_table['medicinalproduct']).reset_index()\n",
      "\tdrug_p.drop('level_1', axis=1, inplace=True)\n",
      "\tdg =  drug_p.groupby('level_0')\n",
      "\tfor name, group in dg:\n",
      "\t\tcol = group.columns - ['level_0']\n",
      "\t\tdf = group[col]; t = [0] * len(col)\n",
      "\t\tfor index, row in df.iterrows(): t += row[col]\n",
      "\t\tdg_v.append(t)\n",
      "\t\tnames_l.append(name)\n",
      "\t\tdrugs_l = col\n",
      "\n",
      "\tdg_v = np.array(dg_v)\n",
      "\tdg_v = preprocessing.binarize(dg_v)\n",
      "\treturn names_l, drugs_l, dg_v\n",
      "\n",
      "def drug_reaction_binary_vec(drug_reaction):\n",
      "\tdr_v = []; drugs_l = []; react_l = [] \n",
      "\tdrug_reaction = pd.get_dummies(drug_reaction['reactionmeddrapt']).reset_index()\n",
      "\tdrug_reaction = drug_reaction.groupby('medicinalproduct')\n",
      "\tfor name, group in drug_reaction: \n",
      "\t\tcol = group.columns - ['safetyreportid', 'medicinalproduct']\n",
      "\t\tdf = group[col]; t = [0] * len(col)\n",
      "\t\tfor index, row in df.iterrows(): t += row[col]\n",
      "\t\tdr_v.append(t)\n",
      "\t\tdrugs_l.append(name)\n",
      "\t\treact_l = col\n",
      "\n",
      "\tdr_v = np.array(dr_v)\n",
      "\tdr_v = preprocessing.binarize(dr_v)\n",
      "\treturn drugs_l, react_l, dr_v\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load ml_alg.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "from sklearn.decomposition import PCA\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "from matplotlib import colors\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pprint import pprint\n",
      "\n",
      "from sklearn.neural_network import BernoulliRBM\n",
      "import rbm as rbm\n",
      "\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn import linear_model, metrics\n",
      "\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sklearn.metrics.pairwise import manhattan_distances\n",
      "from sklearn.metrics.pairwise import euclidean_distances\n",
      "\n",
      "\n",
      "# determine if this should be normal PCA vs RandomPCA\n",
      "def pca_reduction(X, pca):\n",
      "\tX_r = pca.fit(X).transform(X)\n",
      "\t# percentage of variance explained by each of selected components\n",
      "\tprint\"Variance Ratio: \\n{0}\".format(pca.explained_variance_ratio_[:15])\n",
      "\t# components with maximum variance\n",
      "\t# print\"Components...: \\n{0}\".format(pca.components_[:1][0][:10])\n",
      "\treturn pca, X_r\n",
      "\n",
      "\n",
      "def rbm_dnn_scikit(training_data, n_hidden):\n",
      "\trbm = BernoulliRBM(n_components=n_hidden, n_iter=5000)\n",
      "\trbm.fit(training_data)\n",
      "\t# Compute the hidden layer activation probabilities, P(h=1|v=X) : Latent representations of the data\n",
      "\t# Mappings.shape = (n_samples, n_components), training_data.shape = (n_samples, n_features); n_features =n_visible\n",
      "\tmappings = rbm.transform(training_data)\n",
      "\tprint \"n_samples:{0}, n_visible={1}, n_hidden={2}\".format(training_data.shape[0], training_data.shape[1], mappings.shape[1])\n",
      "\t# Weight Matrix : components.shape = (n_components, n_features)\n",
      "\tprint rbm.components_.shape, rbm.components_.T.shape \n",
      "\tpprint(rbm.components_.T)\n",
      "\n",
      "\n",
      "def rbm_dnn(training_data, n_visible, n_hidden, visible_labels):\n",
      "\t# keeping max_epochs low for large samples, local machine processing\n",
      "\tr = rbm.RBM(num_visible = n_visible, num_hidden = n_hidden)\n",
      "\tr.train(training_data, max_epochs = 10)\n",
      "\t\n",
      "\trows = [\"Bias Unit\"] + visible_labels\n",
      "\thidden_labels = [\"Hidden \" + str(i+1) for i in range(n_hidden)]\n",
      "\tcols = [\"Bias Unit\"] + hidden_labels\n",
      "\tmappings = pd.DataFrame(r.weights, index=rows, columns=cols)\n",
      "\n",
      "\t# calculate simalarites of drugs across all hidden nodes\n",
      "\tdists = cosine_similarity(mappings)\n",
      "\tdists = pd.DataFrame(dists, columns=mappings.index)\n",
      "\tdists.index = dists.columns\n",
      "\n",
      "\t# Dimensionality Reduction\t\n",
      "\t# pca, X_r = pca_reduction(mappings.values, PCA())\n",
      "\t# plot_pca_comp_analysis(pca)\n",
      "\n",
      "\treturn mappings, dists, r\n",
      "\n",
      "def rbm_dnn_run(r, test_data, n_visible, n_hidden, visible_labels):\n",
      "\t# See what hidden units are activated\n",
      "\td = r.run_visible(test_data) \n",
      "\n",
      "\trows = [\"Bias Unit\"] + visible_labels\n",
      "\thidden_labels = [\"Hidden \" + str(i+1) for i in range(n_hidden)]\n",
      "\tcols = [\"Bias Unit\"] + hidden_labels\n",
      "\tmappings = pd.DataFrame(r.weights, index=rows, columns=cols)\n",
      "\n",
      "\tprint d[:10]\n",
      "\tprint r.weights[:10]\n",
      "  \n",
      "\txx = dd\n",
      "\n",
      "\t# calculate simalarites of drugs across all hidden nodes\n",
      "\tdists = cosine_similarity(mappings)\n",
      "\tdists = pd.DataFrame(dists, columns=mappings.index)\n",
      "\tdists.index = dists.columns\n",
      "\n",
      "\treturn mappings, dists, r\n",
      "\n",
      "\n",
      "\n",
      "def get_similar(items, dists, n=None):\n",
      "\t# calculates which items are most similar to the input that was provided\n",
      "\titems = [item for item in items if item in dists.columns]\n",
      "\titems_summed = dists[items].apply(lambda row: np.sum(row), axis=1)\n",
      "\titems_summed = items_summed.order(ascending=False)\n",
      "\tranked_items = items_summed.index[items_summed.index.isin(items)==False]\n",
      "\tranked_items = ranked_items.tolist()\n",
      "\tif n is None: return ranked_items\n",
      "\telse: return ranked_items[:n]\n",
      "\n",
      "\n",
      "def plot_pca_comp_analysis(pca_v):\n",
      "    comp_id = [i + 1 for i in range(len(pca_v.explained_variance_ratio_))]             \n",
      "    fig = plt.figure(figsize=(8,5))\n",
      "    plt.plot(comp_id, pca_v.explained_variance_ratio_, 'ro-', linewidth=2)\n",
      "    plt.title('Scree Plot')\n",
      "    plt.xlim(0,25)\n",
      "    plt.xlabel('Principal Component')\n",
      "    plt.ylabel('Proportion of Variance')\n",
      "    plt.savefig('../plots/pca_analysis.png')\n",
      "    \n",
      "    #plt.show()\n",
      "\n",
      "def plot_heat_map(data, x_labels, y_labels, title, image_name):\n",
      "\t# Plot a heatmap representation\n",
      "\tfig, ax = plt.subplots()\n",
      "\theatmap = ax.pcolor(data, cmap=plt.cm.Blues, alpha=0.8)\n",
      "\tfig = plt.gcf()\n",
      "\tfig.set_size_inches(8,11)\n",
      "\t# turn off the frame\n",
      "\tax.set_frame_on(False)\n",
      "\t# put the major ticks at the middle of each cell\n",
      "\tax.set_yticks(np.arange(data.shape[0])+0.5, minor=False)\n",
      "\tax.set_xticks(np.arange(data.shape[1])+0.5, minor=False)\n",
      "\t# want a more natural, table-like display\n",
      "\tax.invert_yaxis()\n",
      "\tax.xaxis.tick_top()\n",
      "\t# Set the labels\n",
      "\tax.set_xticklabels(x_labels, minor=False) \n",
      "\tax.set_yticklabels(y_labels, minor=False)\n",
      "\t# rotate the labels\n",
      "\tplt.xticks(rotation=90)\n",
      "\tax.grid(False)\n",
      "\t# title\n",
      "\t# plt.title(title)\n",
      "\tplt.figtext(.02, .02, title, size='large')\n",
      "\t# Turn off all the ticks\n",
      "\tax = plt.gca()\n",
      "\tfor t in ax.xaxis.get_major_ticks(): \n",
      "\t    t.tick1On = False \n",
      "\t    t.tick2On = False \n",
      "\tfor t in ax.yaxis.get_major_ticks(): \n",
      "\t    t.tick1On = False \n",
      "\t    t.tick2On = False  \n",
      "\n",
      "\tplt.savefig('../plots/' + image_name + '.png')    \n",
      "\tplt.show()\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "from sklearn.decomposition import PCA\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "from matplotlib import colors\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pprint import pprint\n",
      "\n",
      "from sklearn.neural_network import BernoulliRBM\n",
      "import rbm as rbm\n",
      "\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn import linear_model, metrics\n",
      "\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sklearn.metrics.pairwise import manhattan_distances\n",
      "from sklearn.metrics.pairwise import euclidean_distances\n",
      "\n",
      "\n",
      "# determine if this should be normal PCA vs RandomPCA\n",
      "def pca_reduction(X, pca):\n",
      "\tX_r = pca.fit(X).transform(X)\n",
      "\t# percentage of variance explained by each of selected components\n",
      "\tprint\"Variance Ratio: \\n{0}\".format(pca.explained_variance_ratio_[:15])\n",
      "\t# components with maximum variance\n",
      "\t# print\"Components...: \\n{0}\".format(pca.components_[:1][0][:10])\n",
      "\treturn pca, X_r\n",
      "\n",
      "\n",
      "def rbm_dnn_scikit(training_data, n_hidden):\n",
      "\trbm = BernoulliRBM(n_components=n_hidden, n_iter=5000)\n",
      "\trbm.fit(training_data)\n",
      "\t# Compute the hidden layer activation probabilities, P(h=1|v=X) : Latent representations of the data\n",
      "\t# Mappings.shape = (n_samples, n_components), training_data.shape = (n_samples, n_features); n_features =n_visible\n",
      "\tmappings = rbm.transform(training_data)\n",
      "\tprint \"n_samples:{0}, n_visible={1}, n_hidden={2}\".format(training_data.shape[0], training_data.shape[1], mappings.shape[1])\n",
      "\t# Weight Matrix : components.shape = (n_components, n_features)\n",
      "\tprint rbm.components_.shape, rbm.components_.T.shape \n",
      "\tpprint(rbm.components_.T)\n",
      "\n",
      "\n",
      "def rbm_dnn(training_data, n_visible, n_hidden, visible_labels):\n",
      "\t# keeping max_epochs low for large samples, local machine processing\n",
      "\tr = rbm.RBM(num_visible = n_visible, num_hidden = n_hidden)\n",
      "\tr.train(training_data, max_epochs = 10)\n",
      "\t\n",
      "\trows = [\"Bias Unit\"] + visible_labels\n",
      "\thidden_labels = [\"Hidden \" + str(i+1) for i in range(n_hidden)]\n",
      "\tcols = [\"Bias Unit\"] + hidden_labels\n",
      "\tmappings = pd.DataFrame(r.weights, index=rows, columns=cols)\n",
      "\n",
      "\t# calculate simalarites of drugs across all hidden nodes\n",
      "\tdists = cosine_similarity(mappings)\n",
      "\tdists = pd.DataFrame(dists, columns=mappings.index)\n",
      "\tdists.index = dists.columns\n",
      "\n",
      "\t# Dimensionality Reduction\t\n",
      "\t# pca, X_r = pca_reduction(mappings.values, PCA())\n",
      "\t# plot_pca_comp_analysis(pca)\n",
      "\n",
      "\treturn mappings, dists, r\n",
      "\n",
      "def rbm_dnn_run(r, test_data, n_visible, n_hidden, visible_labels):\n",
      "\t# See what hidden units are activated\n",
      "\td = r.run_visible(test_data) \n",
      "\n",
      "\trows = [\"Bias Unit\"] + visible_labels\n",
      "\thidden_labels = [\"Hidden \" + str(i+1) for i in range(n_hidden)]\n",
      "\tcols = [\"Bias Unit\"] + hidden_labels\n",
      "\tmappings = pd.DataFrame(r.weights, index=rows, columns=cols)\n",
      "\n",
      "\tprint d[:10]\n",
      "\tprint r.weights[:10]\n",
      "  \n",
      "\txx = dd\n",
      "\n",
      "\t# calculate simalarites of drugs across all hidden nodes\n",
      "\tdists = cosine_similarity(mappings)\n",
      "\tdists = pd.DataFrame(dists, columns=mappings.index)\n",
      "\tdists.index = dists.columns\n",
      "\n",
      "\treturn mappings, dists, r\n",
      "\n",
      "\n",
      "\n",
      "def get_similar(items, dists, n=None):\n",
      "\t# calculates which items are most similar to the input that was provided\n",
      "\titems = [item for item in items if item in dists.columns]\n",
      "\titems_summed = dists[items].apply(lambda row: np.sum(row), axis=1)\n",
      "\titems_summed = items_summed.order(ascending=False)\n",
      "\tranked_items = items_summed.index[items_summed.index.isin(items)==False]\n",
      "\tranked_items = ranked_items.tolist()\n",
      "\tif n is None: return ranked_items\n",
      "\telse: return ranked_items[:n]\n",
      "\n",
      "\n",
      "def plot_pca_comp_analysis(pca_v):\n",
      "    comp_id = [i + 1 for i in range(len(pca_v.explained_variance_ratio_))]             \n",
      "    fig = plt.figure(figsize=(8,5))\n",
      "    plt.plot(comp_id, pca_v.explained_variance_ratio_, 'ro-', linewidth=2)\n",
      "    plt.title('Scree Plot')\n",
      "    plt.xlim(0,25)\n",
      "    plt.xlabel('Principal Component')\n",
      "    plt.ylabel('Proportion of Variance')\n",
      "    plt.savefig('../plots/pca_analysis.png')\n",
      "    \n",
      "    #plt.show()\n",
      "\n",
      "def plot_heat_map(data, x_labels, y_labels, title, image_name):\n",
      "\t# Plot a heatmap representation\n",
      "\tfig, ax = plt.subplots()\n",
      "\theatmap = ax.pcolor(data, cmap=plt.cm.Blues, alpha=0.8)\n",
      "\tfig = plt.gcf()\n",
      "\tfig.set_size_inches(8,11)\n",
      "\t# turn off the frame\n",
      "\tax.set_frame_on(False)\n",
      "\t# put the major ticks at the middle of each cell\n",
      "\tax.set_yticks(np.arange(data.shape[0])+0.5, minor=False)\n",
      "\tax.set_xticks(np.arange(data.shape[1])+0.5, minor=False)\n",
      "\t# want a more natural, table-like display\n",
      "\tax.invert_yaxis()\n",
      "\tax.xaxis.tick_top()\n",
      "\t# Set the labels\n",
      "\tax.set_xticklabels(x_labels, minor=False) \n",
      "\tax.set_yticklabels(y_labels, minor=False)\n",
      "\t# rotate the labels\n",
      "\tplt.xticks(rotation=90)\n",
      "\tax.grid(False)\n",
      "\t# title\n",
      "\t# plt.title(title)\n",
      "\tplt.figtext(.02, .02, title, size='large')\n",
      "\t# Turn off all the ticks\n",
      "\tax = plt.gca()\n",
      "\tfor t in ax.xaxis.get_major_ticks(): \n",
      "\t    t.tick1On = False \n",
      "\t    t.tick2On = False \n",
      "\tfor t in ax.yaxis.get_major_ticks(): \n",
      "\t    t.tick1On = False \n",
      "\t    t.tick2On = False  \n",
      "\n",
      "\tplt.savefig('../plots/' + image_name + '.png')    \n",
      "\tplt.show()\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Begin Processing of Training Neural Network\n",
      "results = load_from_file()\n",
      "\n",
      "# Shuffle the data and take training data as first 3000 samples\n",
      "results_in = shuffle(results, random_state=0)\n",
      "training_samples = results_in[:5000]\n",
      "print \"retrieved training samples\"\n",
      "\n",
      "drug_table, reaction_table, name_drug_v, le_l = prepare_data(training_samples)\n",
      "n_drugs = len(le_l[1].classes_)\n",
      "n_reactions = len(le_l[2].classes_)\t\n",
      "# Being Neural Network RBM Training: Calculate Cosine Simalarity for how drug are related according to Mapped Weights\n",
      "start = time.time()\n",
      "mappings, dists, rbm_o = rbm_dnn(name_drug_v.values, n_drugs, n_reactions, list(le_l[1].classes_) )\t\n",
      "end = time.time()\n",
      "print \"Training Time= {0}, {1}, {2}\".format(end-start, start, end)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "file version <type 'list'>\n",
        "retrieved training samples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parse binary vector shape: (5000, 6871)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training Time= 1283.77417612, 1418829981.07, 1418831264.85"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# At this point we are ready for analyzing the data\n",
      "# Ideally we would now introduce new outside test samples\n",
      "# Reference test_vectors.py for code analyzation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}